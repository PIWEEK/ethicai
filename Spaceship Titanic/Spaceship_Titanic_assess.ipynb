{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b87ee7c-5556-43a3-a76d-dff6840a3929",
   "metadata": {},
   "source": [
    "Assess Spaceship Titanic with CredoAI - Lens\n",
    "============================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2284e9ef-ac08-4690-890a-f74badc1d462",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train) Number of rows = 8693 and Number of cols = 14\n",
      "(test) Number of rows = 4277 and Number of cols = 13\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from credoai.lens import Lens\n",
    "from credoai.artifacts import ClassificationModel, TabularData\n",
    "from credoai.evaluators import ModelFairness, Performance\n",
    "\n",
    "# For this to work, you need to \"File / Save and export notebook as... / Executable Script\" the notebook\n",
    "import Spaceship_Titanic_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e935883-5829-4bb8-a210-6e1cf4d09aed",
   "metadata": {},
   "source": [
    "Load trained model\n",
    "------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fab41149-f3c2-419f-aa80-ae2ffdea511c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_engineering = Spaceship_Titanic_data.feature_engineering\n",
    "\n",
    "with open('model.jlb', 'rb') as file:\n",
    "    model = joblib.load(file)\n",
    "    \n",
    "processor = model.steps[0][1]\n",
    "drop_target = model.steps[1][1]\n",
    "classifier = model.steps[2][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58ca142-40d7-4cda-a28c-5bd474235e5b",
   "metadata": {},
   "source": [
    "Run a battery of evaluators\n",
    "---------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df1ca67-0d15-4d8c-8855-df42cbe99a12",
   "metadata": {},
   "source": [
    "Prepare the train data for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14132043-ff6e-498d-a571-e3530281ac41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transformed_data = processor.fit_transform(Spaceship_Titanic_data.train_data)\n",
    "dropped_data = drop_target.fit_transform(transformed_data)\n",
    "\n",
    "imputed_data = Spaceship_Titanic_data.imputer.fit_transform(\n",
    "                 Spaceship_Titanic_data.fe_eng.fit_transform(\n",
    "                   Spaceship_Titanic_data.train_data))\n",
    "ages = pd.qcut(imputed_data.Age, 10) # Quantize ages in 10 clusters from min age to max age"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64822d32-cb92-4495-9417-48a4050070e4",
   "metadata": {},
   "source": [
    "Wrap both the model and the data in CredoAI - Lens structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "825aab37-df1f-4065-8ba8-93f26dde3614",
   "metadata": {},
   "outputs": [],
   "source": [
    "credo_model = ClassificationModel(name=\"titanic_default_classifier\",\n",
    "                                  model_like=classifier)\n",
    "credo_data = TabularData(\n",
    "    name=\"titanic-default\",\n",
    "    X=dropped_data,\n",
    "    y=transformed_data.Transported,\n",
    "    sensitive_features=ages\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c710d11-5a1a-4ffd-b00f-b4e92d2ed44a",
   "metadata": {},
   "source": [
    "Create a Lens and execute evaluators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34eebd22-f737-42e1-bc7f-48e3dcc2359f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-19 10:52:53,416 - lens - INFO - Evaluator ModelFairness added to pipeline. Sensitive feature: Age\n",
      "2023-04-19 10:52:53,492 - lens - INFO - Evaluator Performance added to pipeline. \n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<credoai.lens.lens.Lens at 0x7efeeca63880>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens = Lens(model=credo_model, assessment_data=credo_data)\n",
    "\n",
    "# Precission score: % of true positives versus false positives https://credoai-lens.readthedocs.io/en/latest/pages/metrics.html#precision-score\n",
    "# Recall score: probability of positive test if conditions are positive https://credoai-lens.readthedocs.io/en/latest/pages/metrics.html#true-positive-rate\n",
    "\n",
    "metrics = ['precision_score', 'recall_score', 'equal_opportunity']\n",
    "lens.add(ModelFairness(metrics=metrics))\n",
    "lens.add(Performance(metrics=metrics))\n",
    "lens.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eee1e658-2a69-4be1-8648-d5b37a0dbeb5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>equal_opportunity</td>\n",
       "      <td>0.197538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>precision_score_parity</td>\n",
       "      <td>0.090087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recall_score_parity</td>\n",
       "      <td>0.197538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     type     value\n",
       "0       equal_opportunity  0.197538\n",
       "0  precision_score_parity  0.090087\n",
       "1     recall_score_parity  0.197538"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>type</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(-0.001, 13.0]</td>\n",
       "      <td>precision_score</td>\n",
       "      <td>0.741531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(13.0, 18.0]</td>\n",
       "      <td>precision_score</td>\n",
       "      <td>0.804067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(18.0, 21.0]</td>\n",
       "      <td>precision_score</td>\n",
       "      <td>0.740648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(21.0, 24.0]</td>\n",
       "      <td>precision_score</td>\n",
       "      <td>0.771208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(24.0, 27.0]</td>\n",
       "      <td>precision_score</td>\n",
       "      <td>0.792593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(27.0, 30.0]</td>\n",
       "      <td>precision_score</td>\n",
       "      <td>0.830735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(30.0, 35.0]</td>\n",
       "      <td>precision_score</td>\n",
       "      <td>0.797674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(35.0, 40.0]</td>\n",
       "      <td>precision_score</td>\n",
       "      <td>0.827298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(40.0, 49.0]</td>\n",
       "      <td>precision_score</td>\n",
       "      <td>0.822323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(49.0, 79.0]</td>\n",
       "      <td>precision_score</td>\n",
       "      <td>0.822581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(-0.001, 13.0]</td>\n",
       "      <td>recall_score</td>\n",
       "      <td>0.929245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(13.0, 18.0]</td>\n",
       "      <td>recall_score</td>\n",
       "      <td>0.875252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(18.0, 21.0]</td>\n",
       "      <td>recall_score</td>\n",
       "      <td>0.761538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(21.0, 24.0]</td>\n",
       "      <td>recall_score</td>\n",
       "      <td>0.731707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(24.0, 27.0]</td>\n",
       "      <td>recall_score</td>\n",
       "      <td>0.862903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(27.0, 30.0]</td>\n",
       "      <td>recall_score</td>\n",
       "      <td>0.859447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(30.0, 35.0]</td>\n",
       "      <td>recall_score</td>\n",
       "      <td>0.820574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(35.0, 40.0]</td>\n",
       "      <td>recall_score</td>\n",
       "      <td>0.804878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(40.0, 49.0]</td>\n",
       "      <td>recall_score</td>\n",
       "      <td>0.78821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(49.0, 79.0]</td>\n",
       "      <td>recall_score</td>\n",
       "      <td>0.77665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Age             type     value\n",
       "0   (-0.001, 13.0]  precision_score  0.741531\n",
       "1     (13.0, 18.0]  precision_score  0.804067\n",
       "2     (18.0, 21.0]  precision_score  0.740648\n",
       "3     (21.0, 24.0]  precision_score  0.771208\n",
       "4     (24.0, 27.0]  precision_score  0.792593\n",
       "5     (27.0, 30.0]  precision_score  0.830735\n",
       "6     (30.0, 35.0]  precision_score  0.797674\n",
       "7     (35.0, 40.0]  precision_score  0.827298\n",
       "8     (40.0, 49.0]  precision_score  0.822323\n",
       "9     (49.0, 79.0]  precision_score  0.822581\n",
       "10  (-0.001, 13.0]     recall_score  0.929245\n",
       "11    (13.0, 18.0]     recall_score  0.875252\n",
       "12    (18.0, 21.0]     recall_score  0.761538\n",
       "13    (21.0, 24.0]     recall_score  0.731707\n",
       "14    (24.0, 27.0]     recall_score  0.862903\n",
       "15    (27.0, 30.0]     recall_score  0.859447\n",
       "16    (30.0, 35.0]     recall_score  0.820574\n",
       "17    (35.0, 40.0]     recall_score  0.804878\n",
       "18    (40.0, 49.0]     recall_score   0.78821\n",
       "19    (49.0, 79.0]     recall_score   0.77665"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fairness_results = lens.get_results(evaluator_name='ModelFairness')[0]\n",
    "\n",
    "display(fairness_results['results'][0])\n",
    "display(fairness_results['results'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bea01a8e-4427-4354-877d-f9770a84548c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>precision_score</td>\n",
       "      <td>0.790921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recall_score</td>\n",
       "      <td>0.827775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              type     value\n",
       "0  precision_score  0.790921\n",
       "1     recall_score  0.827775"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_label</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.777984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.172225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.222016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.827775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   true_label predicted_label     value\n",
       "0       False           False  0.777984\n",
       "1        True           False  0.172225\n",
       "2       False            True  0.222016\n",
       "3        True            True  0.827775"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "performance_results = lens.get_results(evaluator_name='Performance')[0]\n",
    "# first dataframe is overall metrics\n",
    "display(performance_results['results'][0])\n",
    "# second dataframe is the long form of the confusion matrix\n",
    "display(performance_results['results'][1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
