{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "081ccbdd-3726-4787-a4a8-7d2ae5981a3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import sklearn.datasets\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, FunctionTransformer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, Lars, LarsCV, LassoLars\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from credoai.lens import Lens\n",
    "from credoai.artifacts import ClassificationModel, TabularData, RegressionModel\n",
    "from credoai.evaluators import ModelFairness, Performance\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "ca1938e3-1400-426e-83e1-ad283f641d2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    'Sets the seed of the entire notebook so results are the same every time we run. This is for REPRODUCIBILITY.'\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "def summary(df):\n",
    "    summ = pd.DataFrame(df.dtypes, columns=['dtypes'])\n",
    "    summ['null'] = df.isnull().sum()\n",
    "    summ['unique'] = df.nunique()\n",
    "    summ['min'] = df.min()\n",
    "    summ['median'] = df.median()\n",
    "    summ['max'] = df.max()\n",
    "    summ['mean'] = df.mean()\n",
    "    summ['std'] = df.std()\n",
    "    return summ\n",
    "    \n",
    "set_seed(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "40a3c7b2-4844-49e6-8d6a-5fc0607888bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds = sklearn.datasets.load_diabetes(as_frame=True, scaled=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "15bcc3b0-8417-4781-b432-ac4a71b6e1c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>32.1</td>\n",
       "      <td>101.00</td>\n",
       "      <td>157.0</td>\n",
       "      <td>93.2</td>\n",
       "      <td>38.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.8598</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.6</td>\n",
       "      <td>87.00</td>\n",
       "      <td>183.0</td>\n",
       "      <td>103.2</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.8918</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>93.00</td>\n",
       "      <td>156.0</td>\n",
       "      <td>93.6</td>\n",
       "      <td>41.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.6728</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.3</td>\n",
       "      <td>84.00</td>\n",
       "      <td>198.0</td>\n",
       "      <td>131.4</td>\n",
       "      <td>40.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.8903</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>101.00</td>\n",
       "      <td>192.0</td>\n",
       "      <td>125.4</td>\n",
       "      <td>52.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.2905</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>60.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>28.2</td>\n",
       "      <td>112.00</td>\n",
       "      <td>185.0</td>\n",
       "      <td>113.8</td>\n",
       "      <td>42.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.9836</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>47.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.9</td>\n",
       "      <td>75.00</td>\n",
       "      <td>225.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.4427</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>60.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.9</td>\n",
       "      <td>99.67</td>\n",
       "      <td>162.0</td>\n",
       "      <td>106.6</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3.77</td>\n",
       "      <td>4.1271</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>95.00</td>\n",
       "      <td>201.0</td>\n",
       "      <td>125.2</td>\n",
       "      <td>42.0</td>\n",
       "      <td>4.79</td>\n",
       "      <td>5.1299</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.6</td>\n",
       "      <td>71.00</td>\n",
       "      <td>250.0</td>\n",
       "      <td>133.2</td>\n",
       "      <td>97.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.5951</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>442 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex   bmi      bp     s1     s2    s3    s4      s5     s6\n",
       "0    59.0  2.0  32.1  101.00  157.0   93.2  38.0  4.00  4.8598   87.0\n",
       "1    48.0  1.0  21.6   87.00  183.0  103.2  70.0  3.00  3.8918   69.0\n",
       "2    72.0  2.0  30.5   93.00  156.0   93.6  41.0  4.00  4.6728   85.0\n",
       "3    24.0  1.0  25.3   84.00  198.0  131.4  40.0  5.00  4.8903   89.0\n",
       "4    50.0  1.0  23.0  101.00  192.0  125.4  52.0  4.00  4.2905   80.0\n",
       "..    ...  ...   ...     ...    ...    ...   ...   ...     ...    ...\n",
       "437  60.0  2.0  28.2  112.00  185.0  113.8  42.0  4.00  4.9836   93.0\n",
       "438  47.0  2.0  24.9   75.00  225.0  166.0  42.0  5.00  4.4427  102.0\n",
       "439  60.0  2.0  24.9   99.67  162.0  106.6  43.0  3.77  4.1271   95.0\n",
       "440  36.0  1.0  30.0   95.00  201.0  125.2  42.0  4.79  5.1299   85.0\n",
       "441  36.0  1.0  19.6   71.00  250.0  133.2  97.0  3.00  4.5951   92.0\n",
       "\n",
       "[442 rows x 10 columns]"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale_xf = ColumnTransformer(\n",
    "    [\n",
    "        (\n",
    "            'std_scaler',\n",
    "            StandardScaler(),\n",
    "            ['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']\n",
    "        )\n",
    "    ],\n",
    "    verbose_feature_names_out=False,\n",
    "    remainder='passthrough'\n",
    ").set_output(transform='pandas')\n",
    "\n",
    "def normalize_to_bool(row):\n",
    "    if row.target > 150:\n",
    "        row.target = True\n",
    "    else:\n",
    "        row.target = False\n",
    "\n",
    "    return row\n",
    "\n",
    "def normalize_to_bool_biased(row):\n",
    "    if row.sex == 1.0:\n",
    "        if row.target > 100:\n",
    "            row.target = True\n",
    "        else:\n",
    "            row.target = False\n",
    "    else:\n",
    "        if row.target > 150:\n",
    "            row.target = True\n",
    "        else:\n",
    "            row.target = False\n",
    "    return row\n",
    "        \n",
    "\n",
    "orig_data = ds.frame.copy().apply(normalize_to_bool, axis=1)\n",
    "# bias_data = ds.frame.copy().apply(normalize_to_bool_biased, axis=1)\n",
    "\n",
    "train_orig_data = orig_data.drop(columns=[\"target\"])\n",
    "# train_bias_data = bias_data.drop(columns=[\"target\"])\n",
    "target_orig_data = orig_data.target\n",
    "# target_bias_data = bias_data.target\n",
    "\n",
    "train_orig_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "98fa9e16-bac3-4e66-bfcd-b1f09ebbe3fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_seed(400)\n",
    "train_xf = Pipeline(\n",
    "    [\n",
    "        ('scale_xf', scale_xf),\n",
    "        ('cla', KNeighborsClassifier())\n",
    "    ]\n",
    ").set_output(transform='pandas')\n",
    "\n",
    "params = [\n",
    "    {\n",
    "        'cla': (KNeighborsClassifier(),),\n",
    "        'cla__n_neighbors': [3, 5, 7],\n",
    "        'cla__weights': ['uniform', 'distance']\n",
    "    },\n",
    "    {\n",
    "        'cla': (MLPClassifier(),),\n",
    "        'cla__hidden_layer_sizes': [(80,), (90,), (100,), (120,)],\n",
    "        'cla__activation': ['logistic', 'relu', 'tanh'],\n",
    "        'cla__solver': ['sgd'],\n",
    "        'cla__learning_rate': ['adaptive', 'constant'],\n",
    "        'cla__max_iter': [3500],\n",
    "        'cla__random_state': [1]\n",
    "    },\n",
    "    # {\n",
    "    #     'cla': (DecisionTreeClassifier(),),\n",
    "    #     'cla__criterion': ['gini', 'entropy'],\n",
    "    #     'cla__max_depth': [5, 8, 10]\n",
    "    # },\n",
    "    # {\n",
    "    #     'cla': (RandomForestClassifier(),),\n",
    "    #     'cla__n_estimators': [50, 100, 150],\n",
    "    #     'cla__max_depth': [5, 8, 10]\n",
    "    # }\n",
    "]   \n",
    "\n",
    "gs = GridSearchCV(\n",
    "    estimator=train_xf,\n",
    "    param_grid=params,\n",
    "    scoring='roc_auc',\n",
    "    error_score='raise',\n",
    "    cv=5,\n",
    "    verbose=1,  # Set to 10 to print traces and know the % progress (very verbose)\n",
    "    n_jobs=-2   # -1 uses all CPU cores; you can give a number > 0 to use that number of cores\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "ec8a8090-78ff-4293-98b9-d544b326d909",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    }
   ],
   "source": [
    "gs.fit(train_orig_data, target_orig_data)\n",
    "best_train_xf = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "286a9c4c-38f1-485e-ad4b-0f4843b6fd42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_cla</th>\n",
       "      <th>param_cla__n_neighbors</th>\n",
       "      <th>param_cla__weights</th>\n",
       "      <th>param_cla__activation</th>\n",
       "      <th>param_cla__hidden_layer_sizes</th>\n",
       "      <th>param_cla__learning_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>param_cla__solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.612849</td>\n",
       "      <td>0.292474</td>\n",
       "      <td>0.039977</td>\n",
       "      <td>0.016240</td>\n",
       "      <td>MLPClassifier(max_iter=3500, random_state=1, s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>relu</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>constant</td>\n",
       "      <td>...</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'cla': MLPClassifier(max_iter=3500, random_st...</td>\n",
       "      <td>0.80000</td>\n",
       "      <td>0.911735</td>\n",
       "      <td>0.807812</td>\n",
       "      <td>0.846875</td>\n",
       "      <td>0.854688</td>\n",
       "      <td>0.844222</td>\n",
       "      <td>0.039889</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.898135</td>\n",
       "      <td>0.408366</td>\n",
       "      <td>0.028717</td>\n",
       "      <td>0.003026</td>\n",
       "      <td>MLPClassifier(max_iter=3500, random_state=1, s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>relu</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>...</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'cla': MLPClassifier(max_iter=3500, random_st...</td>\n",
       "      <td>0.80000</td>\n",
       "      <td>0.911735</td>\n",
       "      <td>0.807812</td>\n",
       "      <td>0.846354</td>\n",
       "      <td>0.854688</td>\n",
       "      <td>0.844118</td>\n",
       "      <td>0.039883</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.182012</td>\n",
       "      <td>0.020762</td>\n",
       "      <td>0.042995</td>\n",
       "      <td>0.014868</td>\n",
       "      <td>MLPClassifier(max_iter=3500, random_state=1, s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(80,)</td>\n",
       "      <td>constant</td>\n",
       "      <td>...</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'cla': MLPClassifier(max_iter=3500, random_st...</td>\n",
       "      <td>0.79898</td>\n",
       "      <td>0.903571</td>\n",
       "      <td>0.805729</td>\n",
       "      <td>0.844792</td>\n",
       "      <td>0.860417</td>\n",
       "      <td>0.842698</td>\n",
       "      <td>0.038215</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.771418</td>\n",
       "      <td>0.298018</td>\n",
       "      <td>0.033203</td>\n",
       "      <td>0.003006</td>\n",
       "      <td>MLPClassifier(max_iter=3500, random_state=1, s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(80,)</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>...</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'cla': MLPClassifier(max_iter=3500, random_st...</td>\n",
       "      <td>0.79949</td>\n",
       "      <td>0.903571</td>\n",
       "      <td>0.805729</td>\n",
       "      <td>0.843229</td>\n",
       "      <td>0.859896</td>\n",
       "      <td>0.842383</td>\n",
       "      <td>0.038039</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.210321</td>\n",
       "      <td>0.105831</td>\n",
       "      <td>0.027712</td>\n",
       "      <td>0.010391</td>\n",
       "      <td>MLPClassifier(max_iter=3500, random_state=1, s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(120,)</td>\n",
       "      <td>constant</td>\n",
       "      <td>...</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'cla': MLPClassifier(max_iter=3500, random_st...</td>\n",
       "      <td>0.80102</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.798437</td>\n",
       "      <td>0.853646</td>\n",
       "      <td>0.861458</td>\n",
       "      <td>0.841484</td>\n",
       "      <td>0.036541</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       2.612849      0.292474         0.039977        0.016240   \n",
       "1       2.898135      0.408366         0.028717        0.003026   \n",
       "2       1.182012      0.020762         0.042995        0.014868   \n",
       "3       1.771418      0.298018         0.033203        0.003006   \n",
       "4       1.210321      0.105831         0.027712        0.010391   \n",
       "\n",
       "                                           param_cla param_cla__n_neighbors  \\\n",
       "0  MLPClassifier(max_iter=3500, random_state=1, s...                    NaN   \n",
       "1  MLPClassifier(max_iter=3500, random_state=1, s...                    NaN   \n",
       "2  MLPClassifier(max_iter=3500, random_state=1, s...                    NaN   \n",
       "3  MLPClassifier(max_iter=3500, random_state=1, s...                    NaN   \n",
       "4  MLPClassifier(max_iter=3500, random_state=1, s...                    NaN   \n",
       "\n",
       "  param_cla__weights param_cla__activation param_cla__hidden_layer_sizes  \\\n",
       "0                NaN                  relu                        (100,)   \n",
       "1                NaN                  relu                        (100,)   \n",
       "2                NaN                  tanh                         (80,)   \n",
       "3                NaN                  tanh                         (80,)   \n",
       "4                NaN                  tanh                        (120,)   \n",
       "\n",
       "  param_cla__learning_rate  ... param_cla__solver  \\\n",
       "0                 constant  ...               sgd   \n",
       "1                 adaptive  ...               sgd   \n",
       "2                 constant  ...               sgd   \n",
       "3                 adaptive  ...               sgd   \n",
       "4                 constant  ...               sgd   \n",
       "\n",
       "                                              params split0_test_score  \\\n",
       "0  {'cla': MLPClassifier(max_iter=3500, random_st...           0.80000   \n",
       "1  {'cla': MLPClassifier(max_iter=3500, random_st...           0.80000   \n",
       "2  {'cla': MLPClassifier(max_iter=3500, random_st...           0.79898   \n",
       "3  {'cla': MLPClassifier(max_iter=3500, random_st...           0.79949   \n",
       "4  {'cla': MLPClassifier(max_iter=3500, random_st...           0.80102   \n",
       "\n",
       "  split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0          0.911735           0.807812           0.846875           0.854688   \n",
       "1          0.911735           0.807812           0.846354           0.854688   \n",
       "2          0.903571           0.805729           0.844792           0.860417   \n",
       "3          0.903571           0.805729           0.843229           0.859896   \n",
       "4          0.892857           0.798437           0.853646           0.861458   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.844222        0.039889                1  \n",
       "1         0.844118        0.039883                2  \n",
       "2         0.842698        0.038215                3  \n",
       "3         0.842383        0.038039                4  \n",
       "4         0.841484        0.036541                5  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True,  True, False, False, False, False, False,\n",
       "        True, False, False, False,  True, False,  True,  True,  True,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "        True, False,  True, False, False,  True, False, False, False,\n",
       "        True, False,  True, False, False, False, False, False,  True,\n",
       "       False, False, False, False,  True,  True,  True, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False,  True, False, False, False, False, False,  True,\n",
       "        True, False, False, False,  True, False,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False,  True,  True, False, False, False,  True,  True, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "        True, False, False, False, False,  True,  True,  True,  True,\n",
       "        True,  True, False, False,  True,  True, False, False,  True,\n",
       "       False, False, False,  True,  True, False, False, False, False,\n",
       "        True, False,  True,  True,  True, False,  True,  True, False,\n",
       "        True,  True,  True,  True, False, False,  True, False,  True,\n",
       "       False, False,  True, False, False, False,  True, False,  True,\n",
       "       False,  True, False, False, False,  True,  True,  True, False,\n",
       "       False,  True, False, False, False,  True,  True, False,  True,\n",
       "        True, False,  True,  True,  True,  True,  True, False, False,\n",
       "       False,  True, False, False, False,  True,  True, False,  True,\n",
       "       False,  True, False, False,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True, False,  True, False, False, False,  True,\n",
       "        True,  True, False, False, False, False, False, False, False,\n",
       "        True, False, False, False, False,  True, False, False, False,\n",
       "        True,  True,  True, False,  True,  True,  True, False, False,\n",
       "       False, False, False, False, False,  True,  True,  True,  True,\n",
       "        True,  True,  True, False,  True, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False,  True, False,\n",
       "        True,  True, False,  True,  True, False,  True, False, False,\n",
       "       False,  True, False, False, False,  True,  True, False, False,\n",
       "       False,  True,  True,  True, False,  True, False, False, False,\n",
       "       False, False, False,  True, False,  True,  True, False, False,\n",
       "       False, False, False, False,  True, False, False,  True,  True,\n",
       "       False,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "        True,  True, False,  True,  True, False,  True, False,  True,\n",
       "        True, False, False,  True,  True, False, False, False,  True,\n",
       "        True, False,  True, False,  True, False, False, False,  True,\n",
       "       False, False,  True,  True, False, False,  True, False,  True,\n",
       "        True, False,  True, False, False,  True,  True,  True,  True,\n",
       "        True, False,  True, False, False, False,  True,  True,  True,\n",
       "        True, False,  True, False,  True, False, False, False, False,\n",
       "       False,  True, False,  True, False, False, False,  True,  True,\n",
       "       False,  True,  True,  True,  True, False, False,  True,  True,\n",
       "        True, False, False,  True,  True,  True, False,  True, False,\n",
       "       False,  True,  True, False, False, False, False,  True,  True,\n",
       "       False,  True, False,  True, False,  True, False, False, False,\n",
       "        True, False, False, False, False,  True, False, False,  True,\n",
       "       False])"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(pd.DataFrame(gs.cv_results_).sort_values(by='rank_test_score').reset_index(drop=True).head(5))\n",
    "best_train_xf.predict(train_bias_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "d7a8ef2d-8dd3-4b8a-8604-1aa5015f07fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-21 11:01:27,523 - lens - INFO - Evaluator ModelFairness added to pipeline. Sensitive feature: sex\n",
      "2023-04-21 11:01:27,609 - lens - INFO - Evaluator Performance added to pipeline. \n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>type</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>precision_score</td>\n",
       "      <td>0.761364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>precision_score</td>\n",
       "      <td>0.787879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>recall_score</td>\n",
       "      <td>0.644231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>recall_score</td>\n",
       "      <td>0.8125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sex             type     value\n",
       "0  1.0  precision_score  0.761364\n",
       "1  2.0  precision_score  0.787879\n",
       "2  1.0     recall_score  0.644231\n",
       "3  2.0     recall_score    0.8125"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>equal_opportunity</td>\n",
       "      <td>0.168269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>precision_score_parity</td>\n",
       "      <td>0.026515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recall_score_parity</td>\n",
       "      <td>0.168269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     type     value\n",
       "0       equal_opportunity  0.168269\n",
       "0  precision_score_parity  0.026515\n",
       "1     recall_score_parity  0.168269"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'metadata': {'evaluator': 'ModelFairness',\n",
       "   'sensitive_feature': 'sex',\n",
       "   'dataset_type': 'assessment_data'},\n",
       "  'results': [                     type     value\n",
       "   0       equal_opportunity  0.168269\n",
       "   0  precision_score_parity  0.026515\n",
       "   1     recall_score_parity  0.168269,\n",
       "      sex             type     value\n",
       "   0  1.0  precision_score  0.761364\n",
       "   1  2.0  precision_score  0.787879\n",
       "   2  1.0     recall_score  0.644231\n",
       "   3  2.0     recall_score    0.8125,\n",
       "      true_label predicted_label     value  sens_feat_group\n",
       "   0       False           False  0.839695              1.0\n",
       "   1        True           False  0.355769              1.0\n",
       "   2       False            True  0.160305              1.0\n",
       "   3        True            True  0.644231              1.0\n",
       "   4       False           False  0.810811              2.0\n",
       "   5        True           False  0.187500              2.0\n",
       "   6       False            True  0.189189              2.0\n",
       "   7        True            True  0.812500              2.0]},\n",
       " {'metadata': {'evaluator': 'Performance'},\n",
       "  'results': [              type     value\n",
       "   0  precision_score  0.775401\n",
       "   1     recall_score  0.725000,\n",
       "      true_label predicted_label     value\n",
       "   0       False           False  0.826446\n",
       "   1        True           False  0.275000\n",
       "   2       False            True  0.173554\n",
       "   3        True            True  0.725000]}]"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credo_model = ClassificationModel(name=\"diabetes-classifier\",\n",
    "                                  model_like=best_train_xf)\n",
    "credo_data = TabularData(\n",
    "    name=\"diabetes-test1\",\n",
    "    X=train_orig_data,\n",
    "    y=target_orig_data,\n",
    "    sensitive_features=train_orig_data.sex\n",
    ")\n",
    "\n",
    "lens = Lens(model=credo_model, assessment_data=credo_data)\n",
    "\n",
    "metrics = ['precision_score', 'recall_score', 'equal_opportunity']\n",
    "lens.add(ModelFairness(metrics=metrics))\n",
    "lens.add(Performance(metrics=metrics))\n",
    "lens.run()\n",
    "\n",
    "fairness_results = lens.get_results(evaluator_name='ModelFairness')[0]\n",
    "results = lens.get_results()\n",
    "\n",
    "aggr = fairness_results['results'][0]\n",
    "disaggr = fairness_results['results'][1]\n",
    "\n",
    "display(disaggr)\n",
    "display(aggr)\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "9cdb7726-198f-413f-a325-91054d342b1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0, 0, 'Male'), Text(1, 0, 'Female')]"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph = disaggr[['sex', 'value']] \\\n",
    "             .head(2) \\\n",
    "             .rename(columns={'value': 'Score'}) \\\n",
    "             .replace({2: 'Female', 1: 'Male'})\n",
    "\n",
    "plot = graph.plot.bar(ylabel='score', legend=False, title='Score by Sex')\n",
    "plot.set_xticklabels(graph.sex,\n",
    "                     rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54a7ac2-650c-40bb-ab5c-314b9ae6ad45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b4b68d-8df9-4a86-a4ba-d487b709eebd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
